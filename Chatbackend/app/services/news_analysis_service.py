import json
import random
from concurrent.futures import ThreadPoolExecutor, as_completed
from tqdm import tqdm
import time
import traceback
from datetime import datetime, timedelta
import hashlib
import requests
from openai import OpenAI
from flask import current_app
from ..utils.db_utils import update_analysis_status, get_pending_analysis_tasks
from ..utils.data_utils import validate_and_fix_data, generate_fallback_data
import inspect

# å®¢æˆ·ç«¯å·¥å‚å‡½æ•° - ä»¥å¤„ç†ä¸åŒç‰ˆæœ¬çš„OpenAIåº“
def create_openai_client(api_key, base_url):
    """åˆ›å»ºOpenAIå®¢æˆ·ç«¯ï¼Œå¤„ç†ä¸åŒç‰ˆæœ¬çš„APIå…¼å®¹æ€§"""
    try:
        # æ£€æŸ¥OpenAIç±»çš„åˆå§‹åŒ–å‚æ•°
        params = inspect.signature(OpenAI.__init__).parameters
        valid_params = {}
        
        # æ·»åŠ åŸºæœ¬å‚æ•°
        valid_params['api_key'] = api_key
        if 'base_url' in params:
            valid_params['base_url'] = base_url
        print(f"api_key: {api_key}")
        print(f"base_url: {base_url}")
        # åˆ›å»ºå®¢æˆ·ç«¯ï¼Œä»…ä½¿ç”¨æœ‰æ•ˆå‚æ•°
        print(f"å°è¯•åˆ›å»ºOpenAIå®¢æˆ·ç«¯ï¼Œä½¿ç”¨å‚æ•°: {list(valid_params.keys())}")
        return OpenAI(**valid_params)
        
    except TypeError as e:
        print(f"OpenAIå®¢æˆ·ç«¯åˆå§‹åŒ–å¤±è´¥: {str(e)}")
        
        # å°è¯•æœ€å°åŒ–å‚æ•°åˆ›å»º
        try:
            print("å°è¯•ä»…ä½¿ç”¨api_keyåˆ›å»ºå®¢æˆ·ç«¯")
            return OpenAI(api_key=api_key)
        except Exception as min_e:
            print(f"ä½¿ç”¨æœ€å°åŒ–å‚æ•°åˆ›å»ºå¤±è´¥: {str(min_e)}")
            raise
    except Exception as e:
        print(f"åˆ›å»ºOpenAIå®¢æˆ·ç«¯æ—¶å‘ç”Ÿé”™è¯¯: {str(e)}")
        raise

# åˆ›å»ºMockClientä½œä¸ºå¤‡ç”¨æ–¹æ¡ˆ
class MockClient:
    """å½“æ— æ³•åˆ›å»ºçœŸå®å®¢æˆ·ç«¯æ—¶çš„å¤‡ç”¨æ¨¡æ‹Ÿå®¢æˆ·ç«¯"""
    
    class MockChoice:
        def __init__(self, content=None):
            self.delta = type('obj', (object,), {'content': content})
            
    class MockResponse:
        def __init__(self, content):
            self.choices = [MockClient.MockChoice(content)]
            
    class CompletionsAPI:
        def create(self, **kwargs):
            """æ¨¡æ‹ŸOpenAI APIçš„createæ–¹æ³•ï¼Œæ”¯æŒstream=Trueå‚æ•°"""
            print("ä½¿ç”¨æ¨¡æ‹Ÿå®¢æˆ·ç«¯åˆ›å»ºå®Œæˆï¼Œå°†è¿”å›æ¨¡æ‹Ÿæ•°æ®")
            
            # æ£€æŸ¥æ˜¯å¦éœ€è¦æµå¼å“åº”
            stream = kwargs.get('stream', False)
            
            if stream:
                # æ¨¡æ‹Ÿæµå¼å“åº”ï¼Œè¿”å›ä¸€ä¸ªç”Ÿæˆå™¨
                chunks = [
                    '{"id": "mock-123",',
                    ' "x": 116.3, "y": 39.9,',
                    ' "type": "ç¤¾ä¼š",',
                    ' "title": "' + kwargs.get('messages', [{}])[-1].get('content', 'æ¨¡æ‹Ÿæ–°é—»') + '",',
                    ' "introduction": "è¿™æ˜¯ä¸€æ¡æ¨¡æ‹Ÿæ•°æ®ï¼Œç”¨äºæµ‹è¯•",',
                    ' "spreadSpeed": 0.7,',
                    ' "spreadRange": 0.6,',
                    ' "participants": 0.5,',
                    ' "emotion": { "schema": { "å–œæ‚¦": 0.2, "æœŸå¾…": 0.2, "å¹³å’Œ": 0.2, "æƒŠè®¶": 0.1, "æ‚²ä¼¤": 0.1, "æ„¤æ€’": 0.1, "ææƒ§": 0.05, "åŒæ¶": 0.05 } },',
                    ' "wordCloud": [{"weight": 10, "word": "æµ‹è¯•"}, {"weight": 8, "word": "æ¨¡æ‹Ÿ"}]',
                    '}'
                ]
                
                # è¿”å›æ¨¡æ‹Ÿçš„æµå¼å“åº”å¯¹è±¡
                for chunk in chunks:
                    yield MockClient.MockResponse(chunk)
            else:
                # æ­£å¸¸å“åº”ï¼Œç›´æ¥è¿”å›å®Œæ•´JSON
                return {
                    "id": "mock-123",
                    "x": 116.3, 
                    "y": 39.9,
                    "type": "ç¤¾ä¼š",
                    "title": kwargs.get('messages', [{}])[-1].get('content', 'æ¨¡æ‹Ÿæ–°é—»'),
                    "introduction": "è¿™æ˜¯ä¸€æ¡æ¨¡æ‹Ÿæ•°æ®ï¼Œç”¨äºæµ‹è¯•",
                    "spreadSpeed": 0.7,
                    "spreadRange": 0.6,
                    "participants": 0.5,
                    "emotion": { 
                        "schema": { 
                            "å–œæ‚¦": 0.2, 
                            "æœŸå¾…": 0.2, 
                            "å¹³å’Œ": 0.2, 
                            "æƒŠè®¶": 0.1, 
                            "æ‚²ä¼¤": 0.1, 
                            "æ„¤æ€’": 0.1, 
                            "ææƒ§": 0.05, 
                            "åŒæ¶": 0.05 
                        } 
                    },
                    "wordCloud": [
                        {"weight": 10, "word": "æµ‹è¯•"}, 
                        {"weight": 8, "word": "æ¨¡æ‹Ÿ"}
                    ]
                }
    
    def __init__(self):
        self.chat = self.CompletionsAPI()

class NewsAnalysisService:
    def __init__(self, api_key, base_url="https://api.openai.com/v1", model="gpt-3.5-turbo"):
        """
        åˆå§‹åŒ–æ–°é—»åˆ†ææœåŠ¡
        
        Args:
            api_key (str): APIå¯†é’¥
            base_url (str): APIåŸºç¡€URL
            model (str): ä½¿ç”¨çš„æ¨¡å‹åç§°
        """
        self.model = model
        self.use_mock = False
        
        try:
            # ä½¿ç”¨å·¥å‚å‡½æ•°åˆ›å»ºå®¢æˆ·ç«¯
            print(f"æ­£åœ¨åˆ›å»ºOpenAIå®¢æˆ·ç«¯ (model={model})")
            self.client = create_openai_client(api_key, base_url)
            print("OpenAIå®¢æˆ·ç«¯åˆ›å»ºæˆåŠŸ")
        except Exception as e:
            print(f"OpenAIå®¢æˆ·ç«¯åˆ›å»ºå¤±è´¥ï¼Œå°†ä½¿ç”¨æ¨¡æ‹Ÿå®¢æˆ·ç«¯: {str(e)}")
            self.client = MockClient()
            self.use_mock = True
        
        current_date = datetime.now().strftime("%Y-%m-%d")
        current_date_str = f'ä»Šå¤©æ˜¯{current_date}ï¼Œ'
        tmpprompt = current_date_str + """è¯·ä½ æ‰®æ¼”æ–°é—»åŠ©ç†ï¼Œä¸ºè¿‘æœŸæŒ‡å®šæ–°é—»æ¢³ç†ä¿¡æ¯è„‰ç»œï¼Œå¹¶é‡åŒ–å…³é”®å‚æ•°ã€‚ä¾æ®ç»™å®šæ–°é—»æ ‡é¢˜ï¼Œå‚è€ƒå…³é”®è¯idã€typeã€titleç­‰è¿›è¡Œå¦‚ä¸‹æ“ä½œï¼š

1. **å‚æ•°é‡åŒ–**ï¼šå°†spreadSpeedã€spreadRangeã€participantsã€emotionã€heatTrendã€timelineç›¸å…³å‚æ•°é‡åŒ–è‡³0 - 1åŒºé—´ã€‚å…¶ä¸­emotionå„ç»´åº¦æ•°å€¼æ€»å’Œéœ€ä¸º1ã€‚è¯äº‘è¯æ•°è‡³å°‘50æ¡

2. **ä¿¡æ¯ç»†åŒ–**ï¼šçƒ­åº¦è¶‹åŠ¿å’Œäº‹ä»¶æ—¶é—´çº¿éœ€ä»äº‹ä»¶çˆ†å‘é¦–æ—¥èµ·ï¼Œå°½å¯èƒ½è¯¦ç»†æ¢³ç†ï¼Œç¡®ä¿æ•°æ®çœŸå®å¯é ï¼Œä¸¥ç¦ä¼ªé€ ã€‚

3. **è¾“å‡ºè§„èŒƒ**ï¼šè¯·ä»¥JSONæ ¼å¼è¾“å‡ºç»“æœï¼Œä¸è¦åŒ…å«ä»»ä½•å…¶ä»–æ–‡å­—è¯´æ˜
{
    "id": "ç¼–å·",
    "x": ç»åº¦,
    "y": çº¬åº¦,
    "type": "ç±»å‹",
    "title": "æ–°é—»åç§°",
    "introduction": "å†…å®¹",
    "spreadSpeed": é‡åŒ–å€¼,
    "spreadRange": é‡åŒ–å€¼,
    "participants": çƒ­åº¦å‚ä¸å¤§è‡´äººæ•°é‡åŒ–å€¼,
    "emotion": {
      "schema": {
        "å–œæ‚¦": é‡åŒ–å€¼,
        "æœŸå¾…": é‡åŒ–å€¼,
        "å¹³å’Œ": é‡åŒ–å€¼,
        "æƒŠè®¶": é‡åŒ–å€¼,
        "æ‚²ä¼¤": é‡åŒ–å€¼,
        "æ„¤æ€’": é‡åŒ–å€¼,
        "ææƒ§": é‡åŒ–å€¼,
        "åŒæ¶": é‡åŒ–å€¼
      },
      "rationale": "é˜è¿°æƒ…ç»ªç»´åº¦é‡åŒ–ä¾æ®"
    },
    "stance": {
      "schema": {
        "ç§¯æå€¡å¯¼": é‡åŒ–å€¼,
        "å¼ºçƒˆåå¯¹": é‡åŒ–å€¼,
        "ä¸­ç«‹é™ˆè¿°": é‡åŒ–å€¼,
        "è´¨ç–‘æ¢ç©¶": é‡åŒ–å€¼,
        "ç†æ€§å»ºè®®": é‡åŒ–å€¼,
        "æƒ…ç»ªå®£æ³„": é‡åŒ–å€¼,
        "è§‚æœ›ç­‰å¾…": é‡åŒ–å€¼,
        "æ‰©æ•£ä¼ æ’­": é‡åŒ–å€¼
      },
      "rationale": "é˜è¿°ç«‹åœºç»´åº¦é‡åŒ–ä¾æ®"
    },
    "heatTrend": [
        {"date": "æ—¥æœŸ1", "value": çƒ­åº¦é‡åŒ–å€¼},
        {"date": "æ—¥æœŸ2", "value": çƒ­åº¦é‡åŒ–å€¼},
        {"date": "æ—¥æœŸ3", "value": çƒ­åº¦é‡åŒ–å€¼}
    ],
    "timeline": [
        {"date":"æ—¥æœŸ1", "event": "æ—¶é—´ç‚¹è¯¦ç»†ä»‹ç»"},
        {"date":"æ—¥æœŸ2", "event": "æ—¶é—´ç‚¹è¯¦ç»†ä»‹ç»"}
    ],
    "wordCloud": [
        {"weight": çœŸå®å€¼1, "word": "word1"},
        {"weight": çœŸå®å€¼2, "word": "word2"}
    ]
}

è¯·ç¡®ä¿:
- ç»çº¬åº¦æ˜¯åˆç†çš„åœ°ç†åæ ‡
- æ‰€æœ‰é‡åŒ–å€¼åœ¨0-1èŒƒå›´å†…
- emotionå„ç»´åº¦æ€»å’Œä¸º1
- è‡³å°‘æä¾›5ä¸ªçƒ­åº¦è¶‹åŠ¿æ•°æ®ç‚¹
- è‡³å°‘æä¾›3ä¸ªæ—¶é—´çº¿äº‹ä»¶
- è¯äº‘è¯æ±‡è‡³å°‘50ä¸ª
- æ•°æ®å°½å¯èƒ½çœŸå®å¯é 
"""
        self.sys_prompt = tmpprompt
        
        # APIè°ƒç”¨ç›‘æ§
        self.api_stats = {
            "total": 0,
            "success": 0,
            "timeout": 0,
            "error": 0,
            "rate_limited": 0,
            "avg_duration": 0,
            "durations": []
        }

    def analyze_news(self, news_data):
        """
        åˆ†æå•ä¸ªæ–°é—»
        
        Args:
            news_data (dict): æ–°é—»æ•°æ®ï¼Œå¿…é¡»åŒ…å«'id'å’Œ'title'å­—æ®µ
            
        Returns:
            dict: åˆ†æç»“æœ
        """
        # è·å–æ–°é—»ä¿¡æ¯
        news_id = news_data.get("id")
        news_title = news_data.get("title", "æœªçŸ¥æ ‡é¢˜")
        
        if not news_id:
            raise ValueError("æ–°é—»æ•°æ®ç¼ºå°‘å¿…è¦çš„idå­—æ®µ")
            
        print(f"å¼€å§‹åˆ†ææ–°é—»: {news_title}")
        
        # æ›´æ–°çŠ¶æ€ä¸ºå¤„ç†ä¸­
        update_analysis_status(news_id, "processing")
        
        # å¤„ç†å„ç§å®¢æˆ·ç«¯å¼‚å¸¸æƒ…å†µ
        if self.use_mock:
            print(f"ä½¿ç”¨æ¨¡æ‹Ÿå®¢æˆ·ç«¯åˆ†ææ–°é—»: {news_title}")
            fallback = generate_fallback_data(news_title)
            update_analysis_status(news_id, "completed", fallback)
            return fallback
        elif self.client is None:
            print(f"è­¦å‘Š: APIå®¢æˆ·ç«¯æœªåˆå§‹åŒ–ï¼Œä½¿ç”¨å¤‡ç”¨æ•°æ®: {news_title}")
            fallback = generate_fallback_data(news_title)
            update_analysis_status(news_id, "completed", fallback)
            return fallback
            
        # æ„å»ºæ¶ˆæ¯å†…å®¹
        messages = [
            {'role': 'system', 'content': self.sys_prompt},
            {'role': 'user', 'content': news_title}
        ]
        
        try:
            # æµå¼è°ƒç”¨API
            start_time = time.time()
            
            # è®°å½•APIè°ƒç”¨
            self.api_stats["total"] += 1
            
            # æµå¼è°ƒç”¨API
            try:
                stream = self.client.chat.completions.create(
                    model=self.model,
                    messages=messages,
                    temperature=0.7,
                    stream=True,  # å¯ç”¨æµå¼å¤„ç†
                    extra_body={"enable_search": True}
                )
            except Exception as api_error:
                print(f"APIè°ƒç”¨å¤±è´¥: {str(api_error)}")
                # å°è¯•ä¸å¸¦enable_searchå‚æ•°é‡è¯•ä¸€æ¬¡
                if "extra_body" in str(api_error) or "enable_search" in str(api_error):
                    print("å°è¯•ä¸å¸¦enable_searchå‚æ•°é‡è¯•...")
                    stream = self.client.chat.completions.create(
                        model=self.model,
                        messages=messages,
                        temperature=0.7,
                        stream=True  # å¯ç”¨æµå¼å¤„ç†
                    )
                else:
                    raise
            
            # æ”¶é›†æ‰€æœ‰å“åº”ç‰‡æ®µ
            response_chunks = []
            for chunk in stream:
                if hasattr(chunk.choices[0], 'delta') and hasattr(chunk.choices[0].delta, 'content') and chunk.choices[0].delta.content:
                    response_chunks.append(chunk.choices[0].delta.content)
            
            # è®¡ç®—APIè°ƒç”¨æ—¶é—´
            api_duration = time.time() - start_time
            
            # æ›´æ–°APIç»Ÿè®¡
            self.api_stats["success"] += 1
            self.api_stats["durations"].append(api_duration)
            
            # è®¡ç®—å¹³å‡å“åº”æ—¶é—´
            if self.api_stats["durations"]:
                self.api_stats["avg_duration"] = sum(self.api_stats["durations"]) / len(self.api_stats["durations"])
            
            # æ£€æµ‹æ˜¯å¦å¯èƒ½è¢«é™æµ
            if api_duration > 2 * self.api_stats["avg_duration"] and api_duration > 10:
                self.api_stats["rate_limited"] += 1
                print(f"âš ï¸ å¯èƒ½è¢«é™æµ: è¯·æ±‚è€—æ—¶ {api_duration:.2f}ç§’ï¼Œæ˜¯å¹³å‡æ—¶é—´çš„ {api_duration/self.api_stats['avg_duration']:.1f}å€")
            
            # åˆå¹¶æ‰€æœ‰å“åº”ç‰‡æ®µ
            result_str = "".join(response_chunks)
            
            try:
                # å°è¯•å»é™¤å¯èƒ½çš„markdownæ ¼å¼ ```json ... ```
                if "```json" in result_str:
                    result_str = result_str.split("```json")[1].split("```")[0].strip()
                elif "```" in result_str:
                    result_str = result_str.split("```")[1].split("```")[0].strip()
                
                # è§£æJSON
                result_json = json.loads(result_str)
                
                # éªŒè¯å’Œä¿®æ­£æ•°æ®
                result_json = validate_and_fix_data(result_json, news_title)
                
                # æ›´æ–°çŠ¶æ€ä¸ºå·²å®Œæˆï¼Œä¿å­˜ç»“æœ
                update_analysis_status(news_id, "completed", result_json)
                
                print(f"æ–°é—»'{news_title}'åˆ†æå®Œæˆ")
                return result_json
                
            except json.JSONDecodeError as e:
                print(f"JSONè§£æå¤±è´¥: {str(e)}")
                print(f"åŸå§‹å“åº”: {result_str[:200]}...")  # åªæ˜¾ç¤ºå‰200ä¸ªå­—ç¬¦
                
                # ç”Ÿæˆåå¤‡æ•°æ®
                fallback = generate_fallback_data(news_title)
                
                # æ›´æ–°çŠ¶æ€ä¸ºå¤±è´¥
                update_analysis_status(news_id, "completed", fallback)
                
                return fallback
                
        except Exception as e:
            self.api_stats["error"] += 1
            print(f"åˆ†æå¤±è´¥: {str(e)}")
            print(traceback.format_exc())
            
            # æ›´æ–°çŠ¶æ€ä¸ºå¤±è´¥
            update_analysis_status(news_id, "failed")
            
            # ç”Ÿæˆåå¤‡æ•°æ®
            return generate_fallback_data(news_title)

    def fetch_news_titles(self, api_url="https://api.vvhan.com/api/hotlist/all", max_news_per_platform=5):
        """
        ä»APIè·å–çƒ­é—¨æ–°é—»æ ‡é¢˜
        
        Args:
            api_url (str): APIçš„URLåœ°å€
            max_news_per_platform (int): æ¯ä¸ªå¹³å°æœ€å¤šè·å–çš„æ–°é—»æ•°é‡
            
        Returns:
            dict: åŒ…å«å¹³å°åç§°å’Œå¯¹åº”çƒ­é—¨æ–°é—»æ ‡é¢˜çš„å­—å…¸
        """
        if self.use_mock:
            print("ä½¿ç”¨æ¨¡æ‹Ÿå®¢æˆ·ç«¯è·å–æ–°é—»æ ‡é¢˜")
            # è¿”å›ä¸€äº›æ¨¡æ‹Ÿæ•°æ®
            return {
                "weibo": ["æ¨¡æ‹Ÿæ–°é—»æ ‡é¢˜1", "æ¨¡æ‹Ÿæ–°é—»æ ‡é¢˜2"],
                "toutiao": ["æ¨¡æ‹Ÿæ–°é—»æ ‡é¢˜3", "æ¨¡æ‹Ÿæ–°é—»æ ‡é¢˜4"]
            }
            
        if self.client is None:
            raise ValueError("APIå®¢æˆ·ç«¯æœªåˆå§‹åŒ–")
        
        try:
            response = requests.get(api_url, timeout=10)
            response.raise_for_status()
            
            # è§£æJSONå“åº”
            json_data = response.json()
            
            # ç¡®ä¿æ•°æ®æ ¼å¼æ­£ç¡®
            if not json_data.get('success'):
                raise ValueError("APIè¿”å›æ•°æ®æ ¼å¼é”™è¯¯ï¼Œæœªæ‰¾åˆ°'success'å­—æ®µ")
                
            # æå–æ–°é—»æ ‡é¢˜
            result = {}
            for platform_data in json_data.get('data', []):
                platform_name = platform_data.get('name', 'unknown')
                news_titles = []
                
                for news_item in platform_data.get('data', []):
                    title = news_item.get('title')
                    if title:
                        news_titles.append(title)
                        # è¾¾åˆ°æœ€å¤§æ•°é‡ååœæ­¢æ·»åŠ 
                        if len(news_titles) >= max_news_per_platform:
                            break
                
                if news_titles:
                    result[platform_name] = news_titles
                    
            return result
            
        except requests.exceptions.RequestException as e:
            print(f"è·å–æ–°é—»æ ‡é¢˜å¤±è´¥: {str(e)}")
            return {}
        except (ValueError, KeyError, json.JSONDecodeError) as e:
            print(f"è§£ææ–°é—»æ•°æ®å¤±è´¥: {str(e)}")
            return {}

    def analyze_multiple_news(self, news_items, platforms=None, max_workers=16, timeout=60):
        """
        å¹¶è¡Œåˆ†æå¤šä¸ªæ–°é—»ï¼Œå¸¦æœ‰é¿å…é‡å¤å¤„ç†ã€é”™è¯¯æ¢å¤å’ŒAPIé™æµä¿æŠ¤
        
        Args:
            news_items (list): æ–°é—»æ ‡é¢˜åˆ—è¡¨
            platforms (list, optional): å¯¹åº”çš„å¹³å°åˆ—è¡¨
            max_workers (int): æœ€å¤§çº¿ç¨‹æ•°
            timeout (int): APIè°ƒç”¨è¶…æ—¶æ—¶é—´ï¼ˆç§’ï¼‰
            
        Returns:
            list: åˆ†æç»“æœåˆ—è¡¨
        """
        if self.use_mock:
            print(f"ä½¿ç”¨æ¨¡æ‹Ÿå®¢æˆ·ç«¯æ‰¹é‡åˆ†æ {len(news_items)} æ¡æ–°é—»")
            results = []
            # ç¡®ä¿platformsæœ‰æ•ˆ
            if platforms is None:
                platforms = [None] * len(news_items)
            for title, platform in zip(news_items, platforms):
                if not title:
                    continue
                # ç”Ÿæˆä¸€ä¸ªå”¯ä¸€ID
                news_id = hashlib.md5(title.encode()).hexdigest()
                # ç”Ÿæˆæ¨¡æ‹Ÿæ•°æ®
                result = generate_fallback_data(title)
                result["platform"] = platform
                result["analyzed_at"] = datetime.now().isoformat()
                result["title"] = title
                results.append(result)
            return results
            
        if self.client is None:
            raise ValueError("APIå®¢æˆ·ç«¯æœªåˆå§‹åŒ–")
        
        if not news_items:
            return []
        
        results = []
        
        # ç¡®ä¿platformsæœ‰æ•ˆ
        if platforms is None:
            platforms = [None] * len(news_items)
        elif len(platforms) != len(news_items):
            if len(platforms) < len(news_items):
                platforms = platforms + [None] * (len(news_items) - len(platforms))
            else:
                platforms = platforms[:len(news_items)]
        
        # å»é‡å¹¶å‡†å¤‡è¦å¤„ç†çš„æ–°é—»
        processed_titles = set()
        news_to_process = []
        platform_map = []
        
        for title, platform in zip(news_items, platforms):
            if not title or title in processed_titles:
                continue
            
            processed_titles.add(title)
            news_to_process.append(title)
            platform_map.append(platform)
        
        if not news_to_process:
            return []
        
        # ä¼˜åŒ–çº¿ç¨‹æ•°é‡ï¼Œé¿å…è¿‡å¤šçº¿ç¨‹
        effective_workers = min(max_workers, len(news_to_process))
        print(f"ä½¿ç”¨{effective_workers}ä¸ªçº¿ç¨‹åˆ†æ{len(news_to_process)}æ¡æ–°é—»")
        
        # åˆ†æå•ä¸ªæ–°é—»çš„å‡½æ•°
        def analyze_one_with_retry(title, platform, retry_count=0, max_retries=1):
            news_id = hashlib.md5(title.encode()).hexdigest()
            
            try:
                # æ·»åŠ éšæœºå»¶è¿Ÿåˆ†æ•£è¯·æ±‚
                if retry_count > 0:
                    delay = random.uniform(1, 3)
                    time.sleep(delay)
                    print(f"é‡è¯• '{title}' (å°è¯• {retry_count}/{max_retries})ï¼Œç­‰å¾…{delay:.1f}ç§’")
                
                # åˆ†ææ–°é—»
                news_data = {
                    "id": news_id,
                    "title": title
                }
                
                try:
                    # è®¾ç½®è¶…æ—¶å®šæ—¶å™¨
                    result = self.analyze_news(news_data)
                except TimeoutError:
                    self.api_stats["timeout"] += 1
                    print(f"â±ï¸ åˆ†æ'{title}'è¶…æ—¶ (>{timeout}ç§’)")
                    
                    # å°è¯•é‡è¯•ä¸€æ¬¡
                    if retry_count < max_retries:
                        return analyze_one_with_retry(title, platform, retry_count + 1, max_retries)
                    
                    # ä½¿ç”¨åå¤‡æ–¹æ¡ˆ
                    result = generate_fallback_data(title)
                
                # æ·»åŠ å¹³å°ä¿¡æ¯å’Œåˆ†ææ—¶é—´
                result["platform"] = platform
                result["analyzed_at"] = datetime.now().isoformat()
                result["title"] = title
                
                return result
                
            except Exception as e:
                self.api_stats["error"] += 1
                print(f"åˆ†æ'{title}'å¤±è´¥: {str(e)}")
                
                # å°è¯•é‡è¯•
                if retry_count < max_retries:
                    return analyze_one_with_retry(title, platform, retry_count + 1, max_retries)
                
                # ä½¿ç”¨åå¤‡æ–¹æ¡ˆ
                result = generate_fallback_data(title)
                result["platform"] = platform
                result["analyzed_at"] = datetime.now().isoformat()
                result["title"] = title
                return result
        
        # ä½¿ç”¨çº¿ç¨‹æ± å¹¶è¡Œå¤„ç†
        with ThreadPoolExecutor(max_workers=effective_workers) as executor, \
             tqdm(total=len(news_to_process), desc="åˆ†ææ–°é—»", unit="æ¡") as pbar:
            
            # æäº¤æ‰€æœ‰ä»»åŠ¡
            future_to_news = {
                executor.submit(analyze_one_with_retry, title, platform): (title, platform, i) 
                for i, (title, platform) in enumerate(zip(news_to_process, platform_map))
            }
            
            # å¤„ç†å®Œæˆçš„ä»»åŠ¡
            for future in as_completed(future_to_news):
                title, platform, index = future_to_news[future]
                try:
                    # è·å–ç»“æœï¼Œå¸¦è¶…æ—¶ä¿æŠ¤
                    result = future.result(timeout=timeout + 30)  # ç»™äºˆé¢å¤–çš„å®Œæˆæ—¶é—´
                    results.append(result)
                except Exception as e:
                    print(f"è·å–'{title}'ç»“æœå¤±è´¥: {str(e)}")
                    # æ·»åŠ åå¤‡æ•°æ®
                    fallback = generate_fallback_data(title)
                    fallback["platform"] = platform
                    fallback["analyzed_at"] = datetime.now().isoformat()
                    fallback["title"] = title
                    results.append(fallback)
                
                # æ›´æ–°è¿›åº¦æ¡
                pbar.update(1)
                
                # å®šæœŸè¾“å‡ºAPIçŠ¶æ€
                if pbar.n % 5 == 0 or pbar.n == len(news_to_process):
                    success_rate = 0
                    if self.api_stats["total"] > 0:
                        success_rate = (self.api_stats["success"] / self.api_stats["total"]) * 100
                    avg_time = self.api_stats["avg_duration"]
                    print(f"\nğŸ“Š APIç›‘æ§ - å®Œæˆ: {pbar.n}/{len(news_to_process)} | æˆåŠŸç‡: {success_rate:.1f}% | å¹³å‡æ—¶é—´: {avg_time:.2f}ç§’ | è¶…æ—¶: {self.api_stats['timeout']} | é”™è¯¯: {self.api_stats['error']}")
        
        # è¾“å‡ºæœ€ç»ˆç»Ÿè®¡ä¿¡æ¯
        if self.api_stats["total"] > 0:
            success_rate = self.api_stats["success"] / self.api_stats["total"] * 100
            print(f"APIè°ƒç”¨æˆåŠŸç‡: {success_rate:.1f}%ï¼Œå¹³å‡å“åº”æ—¶é—´: {self.api_stats['avg_duration']:.2f}ç§’")
        
        if self.api_stats["rate_limited"] > 0:
            print(f"âš ï¸ æ£€æµ‹åˆ° {self.api_stats['rate_limited']} æ¬¡å¯èƒ½çš„APIé™æµ")
        
        # æŒ‰å‚ä¸çƒ­åº¦æ’åº
        results.sort(key=lambda x: x.get("participants", 0), reverse=True)
        return results

    # def parallel_process(self, title_url="https://api.vvhan.com/api/hotlist/all", max_workers=16, max_news_per_platform=5):
    #     """
    #     ä»APIè·å–çƒ­é—¨æ–°é—»å¹¶è¿›è¡Œå¹¶è¡Œåˆ†æå¤„ç†ï¼Œå¹¶å®ç°é˜²é‡å¤å¤„ç†å’Œé”™è¯¯æ¢å¤
        
    #     Args:
    #         title_url (str): è·å–æ–°é—»æ ‡é¢˜çš„API URL
    #         max_workers (int): æœ€å¤§çº¿ç¨‹æ•°
    #         max_news_per_platform (int): æ¯ä¸ªå¹³å°æœ€å¤šè·å–çš„æ–°é—»æ•°é‡
            
    #     Returns:
    #         dict: æŒ‰å¹³å°åˆ†ç±»çš„æ–°é—»åˆ†æç»“æœ
    #     """
    #     if self.client is None:
    #         raise ValueError("APIå®¢æˆ·ç«¯æœªåˆå§‹åŒ–")
        
    #     total_start = time.time()
        
    #     # è·å–æ–°é—»æ ‡é¢˜
    #     fetch_start = time.time()
    #     print(f"å¼€å§‹ä»APIè·å–æ–°é—»æ ‡é¢˜...")
    #     news_dict = self.fetch_news_titles(title_url, max_news_per_platform)
    #     fetch_end = time.time()
    #     fetch_duration = fetch_end - fetch_start
        
    #     # ç»Ÿè®¡æ‰€æœ‰æ–°é—»æ ‡é¢˜
    #     all_titles = []
    #     all_platforms = []
    #     for platform, titles in news_dict.items():
    #         for title in titles:
    #             all_titles.append(title)
    #             all_platforms.append(platform)
        
    #     total_news_count = len(all_titles)
    #     print(f"æ–°é—»æ ‡é¢˜è·å–å®Œæˆï¼Œå…± {total_news_count} æ¡ï¼Œè€—æ—¶ {fetch_duration:.2f} ç§’")
        
    #     if not all_titles:
    #         print("æœªèƒ½è·å–åˆ°æ–°é—»æ ‡é¢˜ï¼Œè¿”å›ç©ºç»“æœ")
    #         return {}
        
    #     # å‡†å¤‡åˆ†æç»“æœ
    #     results = {}
    #     for platform in news_dict.keys():
    #         results[platform] = []
        
    #     # å¹¶è¡Œåˆ†ææ‰€æœ‰æ–°é—»
    #     analysis_start = time.time()
    #     analyzed_results = self.analyze_multiple_news(
    #         all_titles, all_platforms, max_workers
    #     )
    #     analysis_end = time.time()
    #     analysis_duration = analysis_end - analysis_start
        
    #     # å°†ç»“æœæŒ‰å¹³å°æ•´ç†
    #     for result in analyzed_results:
    #         platform = result.get("platform", "unknown")
    #         if platform in results:
    #             results[platform].append({
    #                 "title": result.get("title", ""),
    #                 "analysis": result
    #             })
        
    #     # è¾“å‡ºæœ€ç»ˆç»Ÿè®¡ä¿¡æ¯
    #     total_end = time.time()
    #     total_duration = total_end - total_start
        
    #     print(f"\n===== å¹¶è¡Œå¤„ç†ç»Ÿè®¡ä¿¡æ¯ =====")
    #     print(f"æ€»è®¡åˆ†æ {total_news_count} æ¡æ–°é—»ï¼Œæ€»è€—æ—¶ {total_duration:.2f} ç§’")
    #     print(f"- è·å–æ ‡é¢˜è€—æ—¶: {fetch_duration:.2f} ç§’ ({fetch_duration/total_duration*100:.1f}%)")
    #     print(f"- åˆ†æå†…å®¹è€—æ—¶: {analysis_duration:.2f} ç§’ ({analysis_duration/total_duration*100:.1f}%)")
        
    #     if total_news_count > 0:
    #         print(f"- å¹³å‡æ¯æ¡æ–°é—»: {total_duration/total_news_count:.2f} ç§’")
    #         print(f"- å¤„ç†é€Ÿç‡: {total_news_count/total_duration:.2f} æ¡/ç§’")
        
    #     return results

    def process_pending_tasks(self, limit=16):
        """
        å¤„ç†å¾…åˆ†æçš„æ–°é—»
        
        Args:
            limit (int): é™åˆ¶å¤„ç†çš„ä»»åŠ¡æ•°é‡
            
        Returns:
            dict: å¤„ç†ç»“æœç»Ÿè®¡
        """
        if self.client is None:
            raise ValueError("APIå®¢æˆ·ç«¯æœªåˆå§‹åŒ–")
        
        # è·å–å¾…å¤„ç†ä»»åŠ¡
        tasks = get_pending_analysis_tasks(limit)
        
        stats = {
            "total": len(tasks),
            "success": 0,
            "failed": 0
        }
        
        if not tasks:
            print("æ²¡æœ‰å¾…å¤„ç†çš„åˆ†æä»»åŠ¡")
            return stats
        
        print(f"å¼€å§‹å¤„ç† {len(tasks)} æ¡å¾…åˆ†ææ–°é—»")
        
        for task in tasks:
            news_id = task.get("news_id")
            news_data = task.get("news_data", {})
            
            try:
                # åˆ†ææ–°é—»
                self.analyze_news(news_data)
                stats["success"] += 1
            except Exception as e:
                print(f"ä»»åŠ¡å¤„ç†å¤±è´¥ {news_id}: {str(e)}")
                update_analysis_status(news_id, "failed")
                stats["failed"] += 1
        
        print(f"åˆ†æä»»åŠ¡å¤„ç†å®Œæˆ: æˆåŠŸ {stats['success']}, å¤±è´¥ {stats['failed']}")
        return stats

    @staticmethod
    def create_analysis_service():
        """
        åˆ›å»ºå¹¶è¿”å›ä¸€ä¸ªæ–°çš„NewsAnalysisServiceå®ä¾‹
        
        Returns:
            NewsAnalysisService: åˆ†ææœåŠ¡å®ä¾‹
        """
        try:
            api_key = current_app.config.get('QWEN_API_KEY')
            base_url = current_app.config.get('QWEN_BASE_URL')
            model = current_app.config.get('QWEN_MODEL')
            
            if not api_key or not base_url:
                raise ValueError("ç¼ºå°‘APIé…ç½®: éœ€è¦ QWEN_API_KEY å’Œ QWEN_BASE_URL")
                
            print(f"åˆ›å»ºåˆ†ææœåŠ¡: model={model}, base_url={base_url[:15]}...")
            return NewsAnalysisService(api_key, base_url, model)
        except Exception as e:
            print(f"åˆ›å»ºåˆ†ææœåŠ¡å¤±è´¥: {str(e)}")
            traceback.print_exc()
            return None 